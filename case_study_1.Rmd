---
title: "Case Study 1"
subtitle: "AKSTA Statistical Computing"
author: "Bence Vass and Maria-Theresia Dvorak"
date: "2024-04-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1. Ratio of Fibonacci numbers

(a) Write two different R functions which return the sequence $r_i = F_{i+1} /F_i$ for i = 1, . . . , n where $F_i$ is the i-th Fibonacci number, once using **for** and once using **while**.

```{r}
fib_ratio_for <- function(x) {
  fib <- c(1, 1)
  ratio <- c()
  
  for (i in 3:x) {
    ratio <- c(ratio, fib[i - 1] / fib[i - 2])
    fib <- c(fib, fib[i - 1] + fib[i - 2])
  }
  
  return(ratio)
}

print(fib_ratio_for(10))
```

At first we are using a for loop to determine $r_i$. We define a vector `fib` with the first values (1,1) and  an empty vector ratio. The Function `fib_ratio` calculates the Fibonacci number $F_{n-1}+F_{n-2}$ and use them to determine our ratio. Then we append this ratio to the vector `ratio`.

```{r}
fib_ratio_while <- function(x) {
  fib <- c(1, 1) 
  ratio <- c()   
  i <- 3
  while (i <= x) {
    fib[i] <- fib[i - 1] + fib[i - 2]
    ratio <- c(ratio, fib[i - 1] / fib[i - 2])
    i <- i + 1
  }
  
  return(ratio)  
}

print(fib_ratio_while(10))
```

The first steps are the same like before, but we have to initialize our index i too. Here iterates the loop until the certain condition (i <= x) is met. Furthermore it's important to increase i by 1 in our loop.


(b) Benchmark the two functions for $n = 200$ and $n = 2000$ (you can use package **microbenchmark** or package **bench** for this purpose). Which function is faster?

```{r}
library("bench")

n1 <- 200
n2 <- 2000
mark(fib_ratio_while(n1), fib_ratio_for(n1), iterations=100)
mark(fib_ratio_while(n2), fib_ratio_for(n2), iterations=100)
```
Here we are running each function 100 times to get a more accurate estimate of the typical execution time.
This benchmarks indicate that the `fib_ratio_while` function generally performs faster than the `fib_ratio_for` function for both $n = 200$ and $n = 2000$. This suggests that the while loop implementation is more efficient in this case compared to the for loop implementation.


(c) Plot the sequence for $n = 100$. For which value n it starts to converge? What is the number that it converges to?

```{r}
plot(fib_ratio_while(100), col='blue', ylab=expression("r"[i]))
lines(fib_ratio_while(100), col='blue')
fib_ratio_while(100)
```

From the sequence of ratios, we observe that starting from n = 4, the value of $r_n$ gradually approaches the limit of the sequence. By n = 16, we reach the limit, which is approximately 1.618034, known as the golden ratio.


### 2. Gamma function

(a) Write a function to compute the following for n a positive integer using the gamma function in base R. $$
    \rho_n = \frac{Γ((n − 1)/2)}{Γ(1/2)Γ((n − 2)/2)}
    $$
```{r}
p <- function(n){
  gamma((n-1)/2)/(gamma(1/2)*gamma((n-2)/2))
}
```

(b) Try $n = 2000$. What do you observe? Why do you think the observed behavior happens?
```{r}
p(2000)
```

With n=2000 we receive NaN (Not a Number). It suggests that the computation encountered numerical issues, likely due to overflow or underflow errors when dealing with very large numbers.

(c) Write an implementation which can also deal with large values of $n > 1000$. 

```{r}
p_new <- function(n){
  rho <- lgamma((n-1)/2)-(lgamma(1/2)+lgamma((n-2)/2))
  exp(rho)
}
p_new(2000)
```

Here we use `lgamma` to compute the natural logarithm of the gamma function. Then with `exp` we finally get our result. 
This method should handle large values of n effectively without encountering numerical instability issues.

(d) Plot $\rho_n/\sqrt{n}$ for different values of n. Can you guess the limit of $\rho_n / \sqrt{n}$ for $n \rightarrow \infty$?

```{r}
n_values <- seq(1,5000, by=10)
p_sqrt_n  <- function(n){
  p_new(n)/sqrt(n)
}
p_sqrt_n_values <- sapply(n_values, p_sqrt_n)

plot(n_values, p_sqrt_n_values, type = "l", 
     xlab = "n", ylab = "ρn/√n", 
     main = "Plot of ρn/√n for different values of n", col = "blue")
```

We see that the limit of $\rho_n / \sqrt{n}$ for $n \rightarrow \infty$ is 0.39.

### 3. The golden ratio

Two positive numbers x and y with x \> y are said to be in the golden ratio if the ratio between the larger number and the smaller number is the same as the ratio between their sum and the larger number: 
$$\frac{x}{y}=\frac{x+y}{x}$$
(a) Write an R function which computes $\Phi^{n+1}$ using the recursion above (go up to n = 1000).

```{r}
memo <- numeric(1000)  
phi_power <- function(n) {
  if (n == 0) {
    return((sqrt(5) + 1) / 2)  
  } else if (n == 1) {
    return(((sqrt(5) + 1) / 2)^2)  
  } else {
    if (memo[n] == 0) {  
      phi_n <- phi_power(n - 1)
      phi_n_minus_1 <- phi_power(n - 2)
      memo[n] <<- phi_n + phi_n_minus_1  
    }
    return(memo[n])  
  }
}

for (n in 0:10) {
  phi_n_plus_1 <- phi_power(n)
  print(paste("Phi^", n+1, " =", phi_n_plus_1))
}
```

The function checks if $n = 0$, the function returns $\Phi^1 =(\sqrt{5} + 1) / 2$. If $n = 1$, the function returns $\left((\sqrt{5} + 1) / 2\right)^2$.
For $n > 1$, the function recursively calculates $\Phi^{n-1}$ and $\Phi^{n-2}$ by calling itself with $n - 1$ and $n - 2$ as arguments. It then returns the sum of these two values, which corresponds to $\Phi^n + \Phi^{n-1}$ according to the Fibonacci-like relationship.

(b) Write a function which computes this $\Phi^{n+1}$ by simply using the power operator ^. 

```{r}
phi_power_simple <- function(n) {
  phi <- (sqrt(5) + 1) / 2
  return(phi^(n+1))
}

for (n in 0:10) {
  phi_n_plus_1 <- phi_power_simple(n)
  print(paste("Phi^", n+1, " =", phi_n_plus_1))
}
```


(c) Use once == and once all.equal to compare $\Phi^{n+1}$ obtained in a. vs the one obtained in b. for $n = 12, 60, 120, 300$. What do you observe? If there are any differences, what can be the reason?

```{r}
n_values <- c(12, 60, 120, 300)

for (n in n_values) {
  result_a <- phi_power(n)
  print(result_a)
  result_b <- phi_power_simple(n)
  print(result_b)
  
  cat("For n =", n, ", results are equal using ==:", result_a == result_b, "\n")
  
  cat("For n =", n, ", results are equal using all.equal:", all.equal(result_a, result_b), "\n\n")
}
```

From the output, we observe that the results obtained from the two methods, `phi_power` and `phi_power_simple`, are not exactly equal when using the equality operator `==`, but they are considered equal when using the `all.equal` function.
This discrepancy arises due to differences in how floating-point arithmetic is handled in the two methods. The `==` operator checks for exact equality, which may fail due to small rounding errors in floating-point calculations. On the other hand, the `all.equal` function compares values within a specified tolerance level and considers them equal if they are sufficiently close, which is why it returns TRUE for all comparisons.

### 4. Game of craps

A variation of game of craps is played as follows. The player rolls a die and if they roll a 6, they immediately wins. If a 1 is rolled, they immediately loses. If a 2, 3, 4, or 5 is rolled, then this number becomes their “point number.’ ’ The player then has up to three more rolls of the die to roll their point number again. If they do, they win otherwise they lose. Write a program in R to simulate a game of craps. Explain the steps of your program. If the code is not explained, no points will be earned.

### 5. Readable and efficient code

Read over the code below.

(a) Explain (in text) what the code does.

(b) Explain (in text) what you would change to make the code more readable.

(c) Change the code according to a. and wrap it in a function. This function should have at most 10 lines (without adding commands to more lines such as x \<- 1; y \<- 2. Such commands will count as 2 lines!). Check that the function called on the same input outputs the same as the provided code.

```{r}
set.seed(1)
x <- rnorm(1000)
y <- 2 + x + rnorm(1000) df <- data.frame(x, y)

cat("Step", 1, "\n")
fit1 <- lm(y ~ x, data = df[-(1:250),])
p1 <- predict(fit1, newdata = df[(1:250),]) 
r <- sqrt(mean((p1 - df[(1:250),"y"])^2))

cat("Step", 2, "\n")
fit2 <- lm(y ~ x, data = df[-(251:500),])
p2 <- predict(fit2, newdata = df[(251:500),])
r <- c(r, sqrt(mean((p2 - df[(251:500),"y"])^2)))

cat("Step", 3, "\n")
fit3 <- lm(y ~ x, data = df[-(501:750),])
p3 <- predict(fit3, newdata = df[(501:750),])
r <- c(r, sqrt(mean((p3 - df[(501:750),"y"])^2)))

cat("Step", 4, "\n")
fit4 <- lm(y ~ x, data = df[-(751:1000),])
p4 <- predict(fit4, newdata = df[(751:1000),])
r <- c(r, sqrt(mean((p4 - df[(751:1000),"y"])^2))) 
r
```

### 6. Measuring and improving performance

Have a look at the code of the function below. It is a function for performing a Kruskal Wallis test, a robust non-parametric method for testing whether samples come from the same distribution. (Note: we assume no missing values are present in x).

```{r}
kwtest <- function (x, g, ...) {
  if (is.list(x)) {
    if (length(x) < 2L)
      stop("'x' must be a list with at least 2 elements") 
    if (!missing(g))
      warning("'x' is a list, so ignoring argument 'g'") 
    if (!all(sapply(x, is.numeric)))
      warning("some elements of 'x' are not numeric and will be coerced to numeric") 
    k <- length(x)
    l <- lengths(x) 
    if (any(l == 0L))
      stop("all groups must contain data") 
    g <- factor(rep.int(seq_len(k), l))
    x <- unlist(x)
  } else {
    if (length(x) != length(g))
      stop("'x' and 'g' must have the same length")
    g <- factor(g)
    k <- nlevels(g)
    if (k < 2L)
      stop("all observations are in the same group")
  }
  n <- length(x) 
  if (n < 2L)
    stop("not enough observations")
  r <- rank(x)
  TIES <- table(x)
  STATISTIC <- sum(tapply(r, g, sum)^2/tapply(r, g, length)) 
  STATISTIC <- ((12 * STATISTIC/(n * (n + 1)) - 3 * (n + 1))/(1 -
    sum(TIES^3 - TIES)/(n^3 - n)))
  PARAMETER <- k - 1L
  PVAL <- pchisq(STATISTIC, PARAMETER, lower.tail = FALSE)
  names(STATISTIC) <- "Kruskal-Wallis chi-squared" 
  names(PARAMETER) <- "df"
  RVAL <- list(statistic = STATISTIC, parameter = PARAMETER,
      p.value = PVAL, method = "Kruskal-Wallis rank sum test") 
  return(RVAL)
}
```

(a) Write a pseudo code outlining what the function does.

    If x is a list, it contains k vectors with lengths l (l is a list with numbers where every element corresponds to the length of the i-th vector of x).

    `gfgf`

(b) For example data, call the function in two ways: once using x as a list and once using x as a vector with a corresponding g argument. Ensure that the two different function calls return the same thing by aligning the inputs.

    ```{r}

    g = c("A", "B", "C" )
    x = c(
      7, 14, 14, 13, 12, 9, 6, 14, 12, 8,
      15, 17, 13, 15, 15, 13, 9, 12, 10, 8,
      6, 8, 8, 9, 5, 14, 13, 8, 10, 9
      )

    x_list =  list(
      "A"= c(7, 14, 14, 13, 12, 9, 6, 14, 12, 8),
      "B"=c(15, 17, 13, 15, 15, 13, 9, 12, 10, 8),
      "C"=c(6, 8, 8, 9, 5, 14, 13, 8, 10, 9)
            )

    df = data.frame(group = rep(g, each=10), values = x)

    print("====== Built-in ======")
    kruskal.test(values ~ group, data = df) 

    print("====== Exerciese with list param ======")
    kwtest(x_list)

    print("====== Exerciese with list param ======")
    kwtest(x, rep(g, each=10))

    ```

(c) Make a faster version of kwtest() that only computes the Kruskal-Wallis test statistic when the input is a numeric variable x and a variable g which gives the group membership. You can try simplifying the function above or by coding from the mathematical definition (see <https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance>). This function should also perform some checks to ensure the correctness of the inputs (use kwtest() as inspiration).

(d) Consider the following scenario. You have samples available from multiple experiments m = 1000 where you collect the numerical values for the quantity of interest x and the group membership for n individuals. The first 20 individuals in each sample belong to group 1, the following 20 individuals in each sample belong to group 2, the last 10 individuals in each sample belong to group 3. Use the following code to simulate such a data structure:

    ```{r}
    set.seed(1234)
    m <- 1000 # number of repetitions
    n <- 50 # number of individuals
    X <- matrix(rt(m * n, df = 10), nrow = m) grp <- rep(1:3, c(20, 20, 10))
    ```

(e) Write a function which performs the Kruskal-Wallis test using the function stats:::kruskal.test.default() for m repeated experiments and returns a vector of m test statistics. The input of this function are a matrix X with m rows and n columns and a vector g which gives the grouping.

(f) Write a function which performs the Kruskal-Wallis test using the function in point c. for m repeated experiments and returns a vector of m test statistics. The input of this function are a matrix X with m rows and n columns and a vector g which gives the grouping.

(g) Compare the performance of the two approaches using a benchmarking package on the data generated above. Comment on the results.

(h) Now consider vectorizing the function in point c. Compare this approach to the other two. Comment on the results.
